{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBWwQSXuhaF3",
    "outputId": "8dc4057e-6f0a-4949-bf4c-feb680b4c93b",
    "ExecuteTime": {
     "end_time": "2024-12-09T01:18:41.613053Z",
     "start_time": "2024-12-09T01:18:41.608624Z"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T01:18:41.654758Z",
     "start_time": "2024-12-09T01:18:41.648674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "def resize_image_and_bboxes(image, bboxes, target_size):\n",
    "    \"\"\"\n",
    "    修改图像的大小并调整对应的边界框。\n",
    "\n",
    "    :param image: 原始图像 (PIL Image)\n",
    "    :param bboxes: 原始边界框 (Numpy 或 Tensor，形状为 [N, 4])，格式 [x_min, y_min, x_max, y_max]\n",
    "    :param target_size: 目标大小 (宽度, 高度)\n",
    "    :return: 调整大小后的图像和调整后的边界框\n",
    "    \"\"\"\n",
    "    # 获取原始图像的宽度和高度\n",
    "    orig_width, orig_height = image.size\n",
    "\n",
    "    # 调整图像的大小\n",
    "    image_resized = image.resize(target_size, Image.BILINEAR)\n",
    "\n",
    "    # 计算缩放比例\n",
    "    target_width, target_height = target_size\n",
    "    scale_x = target_width / orig_width\n",
    "    scale_y = target_height / orig_height\n",
    "\n",
    "    # 调整边界框\n",
    "    bboxes_resized = bboxes.clone()\n",
    "    bboxes_resized[:, [0, 2]] *= scale_x  # x_min 和 x_max 按照水平比例缩放\n",
    "    bboxes_resized[:, [1, 3]] *= scale_y  # y_min 和 y_max 按照垂直比例缩放\n",
    "\n",
    "    return image_resized, bboxes_resized\n",
    "\n",
    "\n",
    "def filter_invalid_boxes(boxes):\n",
    "        \"\"\"\n",
    "        过滤无效的边界框（宽度或高度为零的框）\n",
    "        \"\"\"\n",
    "        # 计算宽度和高度\n",
    "        width = boxes[:, 2] - boxes[:, 0]\n",
    "        height = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "        # 保留有效的框，宽度和高度大于0\n",
    "        valid_boxes = boxes[(width > 0) & (height > 0) & (boxes[:, 1] > 0) & (boxes[:, 0] > 0)]\n",
    "\n",
    "        # 如果没有有效框，返回一个空的框\n",
    "        if len(valid_boxes) == 0:\n",
    "            return np.empty((0, 4), dtype=np.float32)  # 空框\n",
    "\n",
    "        return valid_boxes\n",
    "\n",
    "\n",
    "def RandomHorizontalFlip(prob, images, targets):\n",
    "    for image, target in zip(images, targets):\n",
    "        if random.random() < prob:\n",
    "            height, width = image.shape[-2:]\n",
    "            image = image.flip(-1)\n",
    "            bbox = target[\"boxes\"]\n",
    "            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n",
    "            target[\"boxes\"] = bbox\n",
    "    return images, targets"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, json_file, transform=None):\n",
    "        \"\"\"\n",
    "        :param img_dir: 存放图像的文件夹路径\n",
    "        :param json_file: 包含标注信息的 JSON 文件路径\n",
    "        :param transform: 需要应用于图像的变换（可选）\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取标注文件\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        # 图像的ID列表\n",
    "        self.img_ids = [anno[\"id\"] for anno in self.annotations]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anno = self.annotations[idx]\n",
    "        img_path = os.path.join(self.img_dir, anno[\"id\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # 处理目标信息\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        if anno[\"region\"]:\n",
    "            boxes = np.array(anno[\"region\"], dtype=np.float32)\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)  # 转换为tensor\n",
    "            labels = torch.tensor([1], dtype=torch.int64)  # 篡改类为类1\n",
    "\n",
    "        else:\n",
    "            boxes = torch.empty((0, 4), dtype=torch.float32)  # 空的2D tensor，形状为 [0, 4]\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)  # 转换为tensor\n",
    "            labels = torch.tensor([0], dtype=torch.int64) # 未篡改类\n",
    "\n",
    "        # 检查框的有效性\n",
    "        if len(boxes) > 0:\n",
    "            # 过滤无效的框（宽度和高度为零的框）\n",
    "            boxes = self.filter_invalid_boxes(boxes)\n",
    "\n",
    "        # 如果没有有效框，跳过该样本\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.empty((0, 4), dtype=torch.float32)  # 空的2D tensor，形状为 [0, 4]\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)  # 转换为tensor\n",
    "            labels = torch.tensor([0], dtype=torch.int64) # 未篡改类\n",
    "            # return self.__getitem__((idx + 1) % len(self))  # 递归调用获取下一个有效样本\n",
    "        \n",
    "        img, boxes = resize_image_and_bboxes(img, boxes, (512, 512))\n",
    "        \n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def filter_invalid_boxes(self, boxes):\n",
    "        \"\"\"\n",
    "        过滤无效的边界框（宽度或高度为零的框）\n",
    "        \"\"\"\n",
    "        # 计算宽度和高度\n",
    "        width = boxes[:, 2] - boxes[:, 0]\n",
    "        height = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "        # 保留有效的框，宽度和高度大于0\n",
    "        valid_boxes = boxes[(width > 0) & (height > 0) & (boxes[:, 1] > 0) & (boxes[:, 0] > 0)]\n",
    "\n",
    "        # 如果没有有效框，返回一个空的框\n",
    "        if len(valid_boxes) == 0:\n",
    "            return np.empty((0, 4), dtype=np.float32)  # 空框\n",
    "\n",
    "        return valid_boxes\n",
    "\n",
    "# 定义测试集的数据集类（与训练集相同，但不需要标签）\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        :param img_dir: 存放测试图像的文件夹路径\n",
    "        :param transform: 需要应用于图像的变换（可选）\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_ids = os.listdir(img_dir)  # 获取所有图片的文件名\n",
    "        self.original_sizes = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        self.original_sizes[img_id] = img.size\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, img_id  # 只返回图像和图片ID\n",
    "\n",
    "# 加载模型\n",
    "def load_model(model, filepath):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()  # 切换到评估模式\n",
    "    print(f\"模型已从 {filepath} 加载\")\n",
    "    return model\n",
    "\n",
    "# 图像转换操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转换为Tensor\n",
    "])\n",
    "\n",
    "# 定义训练数据集和数据加载器\n",
    "train_dataset = CustomDataset(img_dir=\"data/image/train\", json_file=\"data/label_train.json\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# 定义测试数据集和数据加载器\n",
    "test_dataset = TestDataset(img_dir=\"data/image/val\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# 加载预训练的Faster R-CNN模型\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)\n",
    "\n",
    "# model = fasterrcnn_mobilenet_v3_large_fpn(pretained=True)\n",
    "# model = torchvision.models.detection.retinanet_resnet50_fpn_v2(pretrained=True)\n",
    "# in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# model.roi_heads.box_predictor = torchvision.models.detection.retinanet.FastRCNNPredictor(in_features, 2)\n",
    "\n",
    "# 加载训练好的模型\n",
    "# load_model(model, 'model/model.pth')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=1e-4, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# 定义学习率调度器\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n"
   ],
   "metadata": {
    "id": "MIJlXLrUitNE",
    "ExecuteTime": {
     "end_time": "2024-12-09T01:18:42.342728Z",
     "start_time": "2024-12-09T01:18:41.671523Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# 保存模型函数\n",
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"模型已保存到 {filepath}\")\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, dataloader, optimizer, lr_scheduler, num_epochs, save_path=\"model/model.pth\"):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for images, targets in tqdm(dataloader):\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            images, targets = RandomHorizontalFlip(0.95, images, targets)\n",
    "\n",
    "            # 前向传播\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            # 计算总损失\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            epoch_loss += losses.item()\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "        # 每个 epoch 后保存模型\n",
    "        save_model(model, save_path)\n",
    "\n",
    "    # # 每个 epoch 后保存模型\n",
    "    # save_model(model, save_path)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, train_loader, optimizer, lr_scheduler, num_epochs=10)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_Fp-bTClCpi",
    "outputId": "3cefe7bf-3cd5-4d0b-8911-a1b2479ae61e",
    "ExecuteTime": {
     "end_time": "2024-12-09T01:19:11.803588Z",
     "start_time": "2024-12-09T01:18:42.343793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6500 [00:00<?, ?it/s]C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_25352\\865464104.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes = torch.tensor(boxes, dtype=torch.float32)  # 转换为tensor\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_25352\\865464104.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes = torch.tensor(boxes, dtype=torch.float32)  # 转换为tensor\n",
      "  2%|▏         | 107/6500 [00:29<29:17,  3.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 39\u001B[0m\n\u001B[0;32m     33\u001B[0m         save_model(model, save_path)\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;66;03m# # 每个 epoch 后保存模型\u001B[39;00m\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;66;03m# save_model(model, save_path)\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m train_model(model, train_loader, optimizer, lr_scheduler, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "Cell \u001B[1;32mIn[8], line 13\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, dataloader, optimizer, lr_scheduler, num_epochs, save_path)\u001B[0m\n\u001B[0;32m     11\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, targets \u001B[38;5;129;01min\u001B[39;00m tqdm(dataloader):\n\u001B[1;32m---> 13\u001B[0m     images \u001B[38;5;241m=\u001B[39m [image\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[0;32m     14\u001B[0m     targets \u001B[38;5;241m=\u001B[39m [{k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m targets]\n\u001B[0;32m     16\u001B[0m     images, targets \u001B[38;5;241m=\u001B[39m RandomHorizontalFlip(\u001B[38;5;241m0.95\u001B[39m, images, targets)\n",
      "Cell \u001B[1;32mIn[8], line 13\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     11\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, targets \u001B[38;5;129;01min\u001B[39;00m tqdm(dataloader):\n\u001B[1;32m---> 13\u001B[0m     images \u001B[38;5;241m=\u001B[39m [image\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[0;32m     14\u001B[0m     targets \u001B[38;5;241m=\u001B[39m [{k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m targets]\n\u001B[0;32m     16\u001B[0m     images, targets \u001B[38;5;241m=\u001B[39m RandomHorizontalFlip(\u001B[38;5;241m0.95\u001B[39m, images, targets)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 进行推理并生成结果\n",
    "def generate_predictions(model, dataloader, output_json_path):\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        model.eval()  # 切换到评估模式\n",
    "        for images, img_ids in tqdm(dataloader):\n",
    "            images = [image.to(device) for image in images]\n",
    "\n",
    "            # 模型推理\n",
    "            predictions = model(images)\n",
    "\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                prediction = predictions[i]\n",
    "\n",
    "                # 获取预测框和标签\n",
    "                boxes = prediction['boxes'].cpu().numpy()\n",
    "                labels = prediction['labels'].cpu().numpy()\n",
    "                scores = prediction['scores'].cpu().numpy()\n",
    "\n",
    "                # 只保留标签为1的框，即篡改的区域，阈值可根据需要调整\n",
    "                mask = labels == 1\n",
    "                boxes = boxes[mask]\n",
    "                scores = scores[mask]\n",
    "\n",
    "                if len(boxes) > 0:\n",
    "                    # 获取置信度最高的框的索引\n",
    "                    best_idx = np.argmax(scores)\n",
    "                    best_box = boxes[best_idx]\n",
    "                    best_score = scores[best_idx]\n",
    "\n",
    "                    # 将最高置信度的框添加到结果中\n",
    "                    region = [best_box.tolist()]\n",
    "\n",
    "                else:\n",
    "                    region = []\n",
    "\n",
    "                # 将结果添加到列表中\n",
    "                results.append({\"id\": img_id, \"region\": region})\n",
    "\n",
    "    # 将结果保存为JSON文件\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"预测结果已保存到 {output_json_path}\")\n",
    "\n",
    "# 修改模型的分类头部分，将类别数改为2（篡改和未篡改）\n",
    "load_model(model, 'model/model.pth')\n",
    "generate_predictions(model, test_loader, \"output/label_test.json\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
